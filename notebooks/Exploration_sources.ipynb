{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploration sources de données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Racine des fichiers quotidiens\n",
    "BASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv' # {}.csv ça indique à quelle endroit on veur inserer la date (seul element variable) \n",
    "\n",
    "START_DATE = date(2020,1,22)\n",
    "END_DATE = date(2020,3,5)\n",
    "\n",
    "\n",
    "# Répertoire de sauvegarde des fichiers bruts \n",
    "#\"../data --> remonter d'un niveau et aller dans le répertoire data\"\n",
    "RAWFILES_DIR = '../Documents/corona/data/raw/'\n",
    "PROCESSED_DIR = '../Documents/corona/data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boucle de récuperation des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = END_DATE - START_DATE       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = START_DATE + timedelta(days=i)\n",
    "    day_label = day.strftime(\"%m-%d-%Y\")   # pour le \" + .csv\" on converti\n",
    "    #print(day_label)\n",
    "    virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',', parse_dates=['Last Update']) #parse_dates analyse la chaine de caracters a l'interieur... il converti l date dans un langage interieur comprehensible par l'ordi.\n",
    "    virus_df.to_csv(os.path.join(RAWFILES_DIR, day_label + '.csv'), index=False) # pour lire les données tells qu'elles sont \n",
    "#  day.strftime(\"%m-%d-%Y\") on change le format de la date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constitution de la table références lat/log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, \"*.csv\")):\n",
    "    virus_df = pd.read_csv(file, sep=\",\")\n",
    "    if \"Latitude\" in virus_df.columns and \"Longitude\" in virus_df.columns: #ça nous interesse et on veut les garder\n",
    "        df_list.append(virus_df)\n",
    "\n",
    "all_df = pd.concat(df_list)   \n",
    "\n",
    "\n",
    "# Création d'une table de réference pour les lat/long\n",
    "(all_df[['Province/State', 'Country/Region', 'Latitude', 'Longitude']]\n",
    " .drop_duplicates(subset=['Province/State', 'Country/Region'])\n",
    " .sort_values(by=['Country/Region','Province/State'])\n",
    " .to_csv(os.path.join(PROCESSED_DIR, 'lat_long_table.csv'), index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y avait des duplicates ( ex: Croatie et Luxembourg) donc on les a enlevé, on a pris le premier couple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'une table unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la latitude ou la longitude n'est pas dans la colonne on a besoin de rajouter des colonnes\n",
    "\n",
    "df_list = []\n",
    "latlong_df=pd.read_csv(os.path.join(PROCESSED_DIR, \"lat_long_table.csv\"))\n",
    "\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, \"*.csv\")):\n",
    "    virus_df = pd.read_csv(file, sep=\",\")\n",
    "    if not (\"Latitude\" in virus_df.columns and \"Longitude\" in virus_df.columns): #ça nous interesse et on veut les garder\n",
    "        virus_df= virus_df.merge(latlong_df,on=['Province/State', 'Country/Region'], how='left')  \n",
    "    for field, types in data_catalog: \n",
    "        assert virus_df[field.dtypes ==]\n",
    "\n",
    "    df_list.append(virus_df.assign(sources=os.path.basename(file))) #ça nous rajoute une colonne avec la sources\n",
    "    \n",
    "all_df=pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.8257</td>\n",
       "      <td>117.2264</td>\n",
       "      <td>01-22-2020.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.1824</td>\n",
       "      <td>116.4142</td>\n",
       "      <td>01-22-2020.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Last Update  Confirmed  Deaths  \\\n",
       "0          Anhui  Mainland China  1/22/2020 17:00        1.0     NaN   \n",
       "1        Beijing  Mainland China  1/22/2020 17:00       14.0     NaN   \n",
       "\n",
       "   Recovered  Latitude  Longitude         sources  \n",
       "0        NaN   31.8257   117.2264  01-22-2020.csv  \n",
       "1        NaN   40.1824   116.4142  01-22-2020.csv  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region      Last Update  Confirmed  Deaths  \\\n",
       "0          Anhui  Mainland China  1/22/2020 17:00        1.0     NaN   \n",
       "1        Beijing  Mainland China  1/22/2020 17:00       14.0     NaN   \n",
       "2      Chongqing  Mainland China  1/22/2020 17:00        6.0     NaN   \n",
       "3         Fujian  Mainland China  1/22/2020 17:00        1.0     NaN   \n",
       "4          Gansu  Mainland China  1/22/2020 17:00        NaN     NaN   \n",
       "\n",
       "   Recovered  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus_df=pd.read_csv('../Documents/corona/data/raw/01-22-2020.csv', sep=\",\")\n",
    "virus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catalog= (\n",
    "'Last Update':)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
